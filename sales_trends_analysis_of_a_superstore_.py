# -*- coding: utf-8 -*-
"""Sales Trends Analysis of a Superstore .ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1G7-3dru_Yj1QiBBapDnU3i0KtACLM-41

> # Project: Sales Trends Analysis of Superstore  
 Description: This project  analyzes the Superstore Sales Dataset to clean data, identify trends, and visualize insights for a Machine Learning Internship.

># Objective / Goal

Load, clean, and preprocess the dataset.

Understand data structure, missing values, and date formats.

Explore and visualize sales and profit trends across categories and regions.

Extract 3â€“5 key insights supported by visual evidence.

# 1: Importing Libraries
"""

#  Importing Required Libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime as dt

"""# 2: Loading dataset"""

# Loading Dataset
# This dataset havsnon utf-8 characeters so we will use ISO 8859-1 to handle it.
data=pd.read_csv('/content/Sample - Superstore.csv',encoding='ISO-8859-1')

"""# 3: Data Understanding"""

data.shape

data.head(5)

data.columns

data.dtypes

data.isnull().sum()

"""No NUll Values

Summary
"""

data.describe()

""">Outliers"""

sns.boxplot(data['Sales'])

sns.boxplot(data['Profit'])

"""# 4: Data preprocessing

>**Task** Handling missing values
"""

data.isnull().sum().any()

"""As there is no null values,I will introduced a 5% random missingness in the Sales and Profit columns of  Superstore Sales Dataset using np.random.random() with a fixed seed (42) for reproducibility because the original dataset has no natural missing values and the Week 1 task  explicitly requires handling missing values."""

# initialize 5% missing values in sales and profit columns
np.random.seed(42)  # Ensure reproducibility
new_sales = np.random.random(len(data)) < 0.05
new_profit = np.random.random(len(data)) < 0.05
data.loc[new_sales, 'Sales'] = np.nan
data.loc[new_profit, 'Profit'] = np.nan
data.isnull().sum()

# Handle missing values with imputation
# will use mean
# mean works well for numerical features that are not heavily skewed.
data['Sales'] = data['Sales'].fillna(data['Sales'].mean())
data['Profit'] = data['Profit'].fillna(data['Profit'].mean())
print("Missing values after handling:\n", data.isnull().sum())

""">Task Date parsing"""

# Date conversion
data['Order Date'] = pd.to_datetime(data['Order Date'], format='%m/%d/%Y')
data['Ship Date'] = pd.to_datetime(data['Ship Date'], format='%m/%d/%Y')
data.head(2)

"""#5: Exploratory Analysis

> Task: Which category sells best?
"""

# finding best sales by category
# Group data and caluclate total sum
category_sales=data.groupby('Category')['Sales'].sum()
category_sales

"""Technology sells best.

> Taks: Which region has most profit
"""

# finding best region
# Group data and caluclate total sum
region_profit=data.groupby('Region')['Profit'].sum()
region_profit

"""West region has the most profit

# Visualization

 # Task: Sales by Category
"""

# Visualize category_sales by showing total num of sales
plt.figure(figsize=(8,5))
sns.barplot(x=category_sales.index,y=category_sales.values)
plt.title('Sales by Category')
plt.xlabel('Category')
plt.ylabel('Total Sales')
plt.tight_layout()
plt.show()

# visualizing category _sales by showing ratio
import plotly.express as px
fig=px.pie(data,values='Sales',names='Category',title='Sales by Category')
fig.show()

"""> Task: Profit by Region"""

# Visualizing Profit by region by showing total profit.
plt.figure(figsize=(8,5))
palette = ['lightblue', 'mediumseagreen', 'lightslategray', 'sandybrown']
sns.barplot(x=region_profit.index,y=region_profit.values,hue=region_profit,palette=palette)
plt.title('Profit by Region')
plt.xlabel('Region')
plt.ylabel('Total Profit')
plt.tight_layout()
plt.show()

# Visualize profit by region by showing the ratio
fig=px.pie(data,values='Profit',names='Region',title='Profit by Region')
fig.show()

"""# Task: Line graph for sales trend overtime"""

# Calculation of Sales Trend Over Time
sales_over_time = data.groupby(data['Order Date'].dt.to_period('M'))['Sales'].sum().reindex(
pd.period_range(start=data['Order Date'].min().to_period('M'),
end=data['Order Date'].max().to_period('M'),
freq='M')).fillna(0).astype(float)

# Visualization of Sales Trend Over Time
plt.figure(figsize=(9, 6))
sales_over_time.plot(title='Sales Trend Over Time', xlabel='Month', ylabel='Total Sales ($)', rot=45)
plt.tight_layout()
plt.show()

"""Sale is high in month of Nov and Dec every year.

# Task: Heatmap for corelation
"""

#Correlation Heatmap
numeric_data = data.select_dtypes(include=[np.number])
plt.figure(figsize=(9,6))
plt.subplot(2, 2, 4)
sns.heatmap(numeric_data.corr(), annot=True, cmap='coolwarm', fmt='.2f')
plt.title('Correlation Heatmap')
plt.tight_layout()

"""> Few Extra Tasks:

# Relationship between Discount and profit
"""

# Visualize the relationship between discount and profit

plt.figure(figsize=(8, 5))
sns.scatterplot(data=data,x='Discount', y='Profit', )
plt.title('Relationship between Discount and Profit')
plt.xlabel('Discount')
plt.ylabel('Profit')
plt.tight_layout()

"""Negative Corealtion between discount and profit.

#  Relationship between sales and profit
"""

# Visualizing relationship between sales and profit
plt.figure(figsize=(8,5))
sns.scatterplot(data=data,x='Sales',y='Profit')
plt.title('Relationship between Sales and Profit ')
plt.xlabel('Sales')
plt.ylabel('Profit')
plt.tight_layout()
plt.show()

"""Positive corelation  between sales and profit.There are some outliers also in data with a few points showing high sales but low profit

> # 6: Some Insights

- "Best-Selling Category:"  
   Technology leads in total sales, as shown in the bar chart of Sales by Category.

- "Most Profitable Region:"
  East region generates the highest profit, evident from the Profit by Region bar chart.

- "Sales Trend Over Time:"  
   Sales peak during *November and December, visible in the Monthly Sales Trend Line Chart.

- "Impact of Discounts on Profit:"  
   There's a negative correlation (-0.22) between Discount and Profit, as seen in the heatmap, meaning high discounts may reduce profitability.
"""